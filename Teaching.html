<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-141256821-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-141256821-1');
</script>


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>



<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">
<link rel="stylesheet" href="./WanyongQiu_home/jemdoc.css" type="text/css">
<title>Wanyong Qiu's Homepage</title>
<style type="text/css" style="display: none !important;">object:not([type]),object[classid$=":D27CDB6E-AE6D-11cf-96B8-444553540000"],object[classid$=":d27cdb6e-ae6d-11cf-96b8-444553540000"],object[codebase*="swflash.cab"],object[data*=".swf"],embed[type="application/x-shockwave-flash"],embed[src*=".swf"],object[type="application/x-shockwave-flash"],object[src*=".swf"],object[codetype="application/x-shockwave-flash"],iframe[type="application/x-shockwave-flash"],object[classid$=":166B1BCA-3F9C-11CF-8075-444553540000"],object[codebase*="sw.cab"],object[data*=".dcr"],embed[type="application/x-director"],embed[src*=".dcr"],object[type="application/x-director"],object[src*=".dcr"],object[classid$=":15B782AF-55D8-11D1-B477-006097098764"],object[codebase*="awswaxf.cab"],object[data*=".aam"],embed[type="application/x-authorware-map"],embed[src*=".aam"],object[type="application/x-authorware-map"],object[src*=".aam"],object[classid*="32C73088-76AE-40F7-AC40-81F62CB2C1DA"],object[type="application/ag-plugin"],object[type="application/x-silverlight"],object[type="application/x-silverlight-2"],object[source*=".xaml"],object[sourceelement*="xaml"],embed[type="application/ag-plugin"],embed[source*=".xaml"]{display: none !important;}</style></head>
<body>
<table summary="Table for page layout." id="tlayout">
<tbody><tr valign="top">
<td id="layout-menu">

<style>
    .menu-item {
        margin: 10px; 
    }
</style>
	
<div class="menu-category">BHE-AIM-TMMI</div>

	
<div class="menu-item"><a class="current" href="index.html">Home</a></div>
<div class="menu-item"><a href="https://bhe-lab.org/">BHE</a></div>
<div class="menu-item"><a href="People.html">Team</a></div>
<div class="menu-item"><a href="Publications.html">Publications</a></div>
<div class="menu-item"><a href="Activity.html">Activities</a></div>
<div class="menu-item"><a href="Projects.html">Projects</a></div>
<div class="menu-item"><a href="Prizes.html">Awards</a></div>
<div class="menu-item"><a href="Library.html">Resources</a></div>
<div class="menu-item"><a href="Teaching.html">Teaching (Chinese)</a></div>
<div class="menu-item"><a href="Blog.html">Blog (Chinese)</a></div>
	
</td>
<td id="layout-content">
<p><br></p>


<h2><b>Teaching</b></h2>
<p>Here I want to share some of the teaching projects that I am interested in and will be working on, and I really hope to share them with my students in future classes.</p>

<h3><b>Courses</b></h3>
<h3><b>隐私计算医疗应用理论与方法</b></h3>
	
<ol>
<li><p>
	隐私计算
<ul>
<li><p> 第1部分（隐私加密计算）
	<a class="badge badge-success" href="./WanyongQiu_home/Healthcare_privacy.pdf">Slides</a>
	<a onclick="show('encryption ')"><font color="red"><b>see excerpt</b></font></a>
<div id="encryption " style="display:none; color:#4FA1EA; font-style:italic"> 
"是指使用密码学工具在安全协议层次构建隐私计算协议，从而实现多个数据拥有方在相互保护隐私的前提下，协同完成计算任务。代表技术：安全多方计算。"<br/>
"隐私计算最初是作为隐私加密计算进行研究的。随着秘密共享、不经意传输、混淆电路和同态加密等密码学工具的发展，隐私加密计算仍有广泛的使用场景和发展潜力。"<br/>
</div>
</p></li>
	
<li><p> 第2部分（隐私保护计算）
	<a class="badge badge-success" href="./WanyongQiu_home/Healthcare_privacy.pdf">Slides</a>
	<a onclick="show('preserving')"><font color="red"><b>see excerpt</b></font></a>
<div id="preserving" style="display:none; color:#4FA1EA; font-style:italic"> 
"按照发展轨迹、算法基础和应用特点，隐私保护计算目前主要分为差分隐私、可信执行环境和联邦学习三种技术。"<br/>
"为了在计算任务中对隐私进行更加精细的分析和控制，隐私计算的研究逐渐脱离出隐私加密计算的密码学范畴，在更加广泛的技术和应用场景下研究：计算前对数据的安全获取和管理、计算过程中对数据隐私的保护、计算完成后对生成/发布（数据/模型）的隐私保护与安全评估。"<br/>
</div> 
</p></li>
</ul>
</p></li>

<li><p>
	隐私保护计算
<ul>
<li><p> 第1讲（匿名模型）
	<a class="badge badge-success" href="./WanyongQiu_home/Differential_privacy.pdf">Slides</a>
	<a onclick="show('Anonymization')"><font color="red"><b>see excerpt</b></font></a>
<div id="Anonymization" style="display:none; color:#4FA1EA; font-style:italic"> 
"匿名模型（Anonymization Model）旨在通过处理和转换原始数据，减少或消除个人标识信息的暴露，以保护个体隐私。"<br/>
"k-匿名（k-Anonymity）： 保证数据集中每个个体的记录在至少k个记录中不可区分，以防止个体识别。"<br/>
"数据去标识化（Data De-Identification）： 通过删除或伪名化个人身份信息，使数据不再直接指向个人。”
</div>
</p></li>
	
<li><p> 第2讲（差分隐私）
	<a class="badge badge-success" href="./WanyongQiu_home/Differential_privacy.pdf">Slides</a>
	<a onclick="show('DP')"><font color="red"><b>see excerpt</b></font></a>
<div id="DP" style="display:none; color:#4FA1EA; font-style:italic"> 
"差分隐私（Differential Privacy）是隐私保护领域中的一种严格定义，其通过在数据查询或计算结果中引入随机噪声，提供对个体数据的隐私保障。"<br/>
"形式化地，差分隐私保证了在两个相邻数据库（即仅相差一个个体记录的数据库）上执行同一算法时，输出结果的概率分布不会显著不同，从而保护个体隐私。差分隐私通常通过隐私参数ϵ来量化隐私损失，ϵ值越小，隐私保护越强。"<br/>
"差分隐私的目标是确保任何个体数据的加入或删除对分析结果的影响微乎其微，从而限制潜在的隐私泄露风险。”
</div>
</p></li>
	
<li><p> 第3讲（可信执行环境）
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
	<a onclick="show('TEE')"><font color="red"><b>see excerpt</b></font></a>
<div id="TEE" style="display:none; color:#4FA1EA; font-style:italic"> 
"可信执行环境（Trusted Execution Environment, TEE）是一种专门的计算环境，旨在通过硬件和软件相结合的方式，提供隔离的、安全的执行空间，用于保护敏感数据和代码免受外部攻击。"<br/>
"TEE与主操作系统分离，并通过硬件级别的隔离机制防止未经授权的访问和修改。其核心特性包括数据的机密性、完整性和执行过程的隐私保护，确保即便是操作系统或高权限的恶意攻击者也无法干预其中运行的程序或访问其处理的敏感信息。"<br/>
</div>
</p></li>
	
<li><p> 第4讲（联邦学习）
	<a class="badge badge-success" href="./WanyongQiu_home/Federated_learning.pdf">Slides</a>
	<a onclick="show('FL')"><font color="red"><b>see excerpt</b></font></a>
<div id="FL" style="display:none; color:#4FA1EA; font-style:italic"> 
"联邦学习（Federated Learning）是一种分布式机器学习框架，旨在在多个分散的数据源上进行模型训练，而无需将数据集中到一个中心位置。其核心思想是通过在各个本地设备或机构（如手机、医院）上分别训练模型，并将模型参数（而非原始数据）上传至中央服务器进行聚合，构建一个全局模型。"<br/>
"即‘数据不动，模型动’，这一过程保护了数据隐私和安全，因为原始数据始终保留在本地，避免了数据传输带来的隐私泄露风险。联邦学习有效解决了数据孤岛和隐私保护的问题，尤其适用于医疗等对数据安全性要求高的领域。"<br/>
</div>
</p></li>
</ul>
</p></li>

<li><p>
	心理生理隐私计算
<ul>
<li><p> 第1讲（心理生理计算）
	<a class="badge badge-success" href="./WanyongQiu_home/Differential_privacy.pdf.pdf">Slides</a>
	<a onclick="show('Psychophysiological')"><font color="red"><b>see excerpt</b></font></a>
<div id="Psychophysiological" style="display:none; color:#4FA1EA; font-style:italic"> 
"心理生理计算（Psychophysiological Computing）是一个多学科交叉领域，结合心理学、生理学与计算机科学，旨在通过测量和分析个体的生理信号（如心率、皮肤电活动、脑电波等）来量化其心理状态。"<br/>
"心理生理计算为理解和量化人类的心理状态提供了一种客观的、生理学基础的方法，应用于情绪计算、认知评估、精神心理疾病智能诊疗、健康监测等领域。"<br/>
</div>
</p></li>
	
<li><p> 第2讲（心理生理隐私定义）
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
	<a onclick="show('Privacy')"><font color="red"><b>see excerpt</b></font></a>
<div id="Privacy" style="display:none; color:#4FA1EA; font-style:italic"> 
"心理生理隐私（Psychophysiological Privacy）是指在涉及个体心理与生理状态的生物数据（如心率、皮肤电反应、脑电波等）的收集、存储、处理和分析过程中，保护个体身份、情感状态、心理健康和生理反应的隐私权。"<br/>
"由于心理生理数据能够深刻反映个体的内在状态，其敏感性超出一般数据隐私，可能导致个体面临歧视、标签化或健康信息的非自愿泄露。"<br/>
</div>
</p></li>

<li><p> 第3讲（心理生理隐私机制）
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
	<a onclick="show('PPC')"><font color="red"><b>see excerpt</b></font></a>
<div id="PPC" style="display:none; color:#4FA1EA; font-style:italic"> 
"心理生理隐私计算（Psychophysiological Privacy Computing）是一个新兴的隐私概念以及跨学科的研究领域，结合心理生理学、隐私保护和计算技术，旨在通过算法和系统设计保护个体的心理生理数据在收集、处理和分析过程中的隐私安全。"<br/>
"随着可穿戴设备和生物传感器技术的发展，心理生理数据（如心率、皮肤电反应、脑电波等）变得越来越容易获取，这引发了对如何有效保护这些敏感数据的广泛关注。"<br/>
</div>
</p></li>
	
<li><p> 第4讲（安全与隐私度量）
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
	<a onclick="show('quantification')"><font color="red"><b>see excerpt</b></font></a>
<div id="quantification" style="display:none; color:#4FA1EA; font-style:italic"> 
"在心理生理隐私计算的研究中，安全性和隐私度量是评估和验证计算前、计算过程中以及计算后的数据保护有效性的关键因素。"<br/>
"涉及在数据收集前进行风险评估和隐私需求分析，在计算过程中实施隐私保护机制与实时监控，以及在计算后评估隐私损失和数据再识别风险，以确保个体数据的隐私和安全得到有效保护。"<br/>
</div>
</p></li>
</ul>
</p></li>

<li><p>
	隐私计算平台
<ul>
<li><p> 第1讲（FATE 安全计算平台）微众
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
</p></li>
<li><p> 第2讲（PrivPy 多方计算平台）华控
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
</p></li>
<li><p> 第3讲（MesaTEE 安全计算平台）百度
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
</p></li>
<li><p> 第4讲（PySyft框架）OpenMined
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
</p></li>
<li><p> 第5讲（FedLearner框架）字节
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
</p></li>
</ul>
</p></li>
	
<li><p>
	隐私计算医疗应用
<ul>
	
<li><p>第1部分（隐私计算在医疗领域的应用：医疗机构）
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
	<a onclick="show('application1')"><font color="red"><b>see excerpt</b></font></a>
<div id="application1" style="display:none; color:#4FA1EA; font-style:italic"> 
"研究致力于通过实现安全的数据共享和联合分析，利用隐私保护技术（如联邦学习和差分隐私）在不同医疗机构之间进行协作，从而推动临床研究和公共卫生决策，同时保障患者隐私和数据安全。"<br/>
</div>
</p></li>
	
<li><p>第2部分（隐私计算在医疗领域的应用：医疗物联网）
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
	<a onclick="show('application2')"><font color="red"><b>see excerpt</b></font></a>
<div id="application2" style="display:none; color:#4FA1EA; font-style:italic"> 
"研究旨在通过利用隐私保护技术（如联邦学习和差分隐私）来确保在医疗物联网设备中收集和传输的敏感健康数据的安全性与隐私性，从而支持实时监测和智能决策，同时保护患者的个人信息。"<br/>
</div>
</p></li>
	
</ul>
</p></li>

	
<li><p>
	中国数据保护法律概况
<ul>
<li><p>第1部分（《个人信息保护法》与数据保护）
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
</p></li>
<li><p>第2部分（《数据安全法》与数据保护）
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
</p></li>
<li><p>第3部分（《网络安全法》与数据保护）
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
</p></li>
</ul>
	
</p></li>	
</ol>

<h3><b>Talks (Delivered to Undergraduates)</b></h3>

<ol>
<li><p>
	医疗数据伦理问题
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
</p></li>
<li><p>
	医疗数据个人隐私
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
</p></li>
<li><p>
	医疗数据权利
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
</p></li>
<li><p>
	医疗数据使用
	<a class="badge badge-success" href="./WanyongQiu_home/Prevacy_preserving.pdf">Slides</a>
</p></li>
</ol>	


	
<div id="footer">
<div id="footer-text">Copyright (c) 2021 Wanyong Qiu. All rights reserved.</div>
</div>

</td>
</tr>
</tbody></table>


<style type="text/css">embed[type*="application/x-shockwave-flash"],embed[src*=".swf"],object[type*="application/x-shockwave-flash"],object[codetype*="application/x-shockwave-flash"],object[src*=".swf"],object[codebase*="swflash.cab"],object[classid*="D27CDB6E-AE6D-11cf-96B8-444553540000"],object[classid*="d27cdb6e-ae6d-11cf-96b8-444553540000"],object[classid*="D27CDB6E-AE6D-11cf-96B8-444553540000"]{	 display: none !important;}</style> </body></html>

<script language="javascript" type="text/javascript">
function showHide(obj) {
	var el = document.getElementById(obj);
	if ( el.style.display != 'block' ) {
		el.style.display = 'block';
	}
	else {
		el.style.display = 'none';
	}
}
</script>

<script  type="text/javascript">
function show(obj){
 if(document.getElementById(obj).style.display=="block"){
  document.getElementById(obj).style.display="none";
 }else{
  document.getElementById(obj).style.display="block";
 }
}
</script>
